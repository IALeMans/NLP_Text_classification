{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multi-Class Text Classification Model Comparison and Selection.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PptECX0_LsEU",
        "colab_type": "code",
        "outputId": "b51dfc42-16bf-40e6-c8e1-e9ea180bf9c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"popular\")\n",
        "\n",
        "import logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "import gensim\n",
        "#import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mqMtpvTLtoY",
        "colab_type": "text"
      },
      "source": [
        "# Multi-Class Text Classification Model Comparison and Selection\n",
        "inspired by https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568\n",
        "\n",
        "dataset used for multiclassification task : large data set of Stack Overflow questions and tags, publicly available at this Cloud Storage URL: https://storage.googleapis.com/tensorflow-workshop-examples/stack-overflow-data.csv."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxrBCMT2Ax3u",
        "colab_type": "text"
      },
      "source": [
        "## Dataset preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgkeYAVCAYqm",
        "colab_type": "text"
      },
      "source": [
        "### loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzauinpnAT0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('https://storage.googleapis.com/tensorflow-workshop-examples/stack-overflow-data.csv')\n",
        "df = df[pd.notnull(df['tags'])]\n",
        "print(df.head(10))\n",
        "print(df['post'].apply(lambda x: len(x.split(' '))).sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiShZ53C_kao",
        "colab_type": "text"
      },
      "source": [
        "### exploring the dataset\n",
        "- Is dataset balanced ?\n",
        "- Dataset content"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFXVE8ZkL7UP",
        "colab_type": "code",
        "outputId": "8b25b75d-4451-48a3-835c-05123e4016dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "my_tags = ['java','html','asp.net','c#','ruby-on-rails','jquery','mysql','php','ios','javascript','python','c','css','android','iphone','sql','objective-c','c++','angularjs','.net']\n",
        "plt.figure(figsize=(10,4))\n",
        "df.tags.value_counts().plot(kind='bar');"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmAAAAExCAYAAADbUR4fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIiI6Nj/B9x62m64qqB9AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izIygn2tMMEZ",
        "colab_type": "code",
        "outputId": "b5c46fbc-72bb-4a68-f21d-84ad2dcf7a7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "def print_plot(index):\n",
        "    example = df[df.index == index][['post', 'tags']].values[0]\n",
        "    if len(example) > 0:\n",
        "        print(example[0])\n",
        "        print('Tag:', example[1])\n",
        "print_plot(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "when we need interface c# <blockquote>    <strong>possible duplicate:</strong><br>   <a href= https://stackoverflow.com/questions/240152/why-would-i-want-to-use-interfaces >why would i want to use interfaces </a>   <a href= https://stackoverflow.com/questions/9451868/why-i-need-interface >why i need interface </a>    </blockquote>     i want to know where and when to use it     for example    <pre><code>interface idemo {  // function prototype  public void show(); }  // first class using the interface class myclass1 : idemo {  public void show()  {   // function body comes here   response.write( i m in myclass );  }  }  // second class using the interface class myclass2 : idemo {  public void show()   {   // function body comes here   response.write( i m in myclass2 );   response.write( so  what  );  } </code></pre>   these two classes has the same function name with different body. this can be even achieved without interface. then why we need an interface where and when to use it\n",
            "Tag: c#\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgaGwgJBMRGQ",
        "colab_type": "code",
        "outputId": "9eb8f64f-a02a-45ce-d07a-de43265ba527",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print_plot(30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "how to chain expressions inside ngclass when using the {...}[] form  how can i add another expression to an <code>ng-class</code> directive that uses this form:   <pre><code>ng-class= {true: loading   false: loading-done }[data.loader===null]  </code></pre>   i d like to add something like this to the list:   <pre><code>{highlight:isspecial} </code></pre>   is it possible without expanding the first expression     thanks.\n",
            "Tag: angularjs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSflhp5jAOly",
        "colab_type": "text"
      },
      "source": [
        "### cleanning dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cduP-qwEMZB9",
        "colab_type": "code",
        "outputId": "70e5e4b8-b0c9-4ee0-e1ee-653c4ca3b7f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "        text: a string\n",
        "        \n",
        "        return: modified initial string\n",
        "    \"\"\"\n",
        "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
        "    text = text.lower() # lowercase text\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
        "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
        "    return text\n",
        "    \n",
        "df['post'] = df['post'].apply(clean_text)\n",
        "print_plot(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "need interface c# possible duplicate would want use interfaces need interface want know use example interface idemo function prototype public void show first class using interface class myclass1 idemo public void show function body comes responsewrite myclass second class using interface class myclass2 idemo public void show function body comes responsewrite myclass2 responsewrite two classes function name different body even achieved without interface need interface use\n",
            "Tag: c#\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuZVqZpEMemq",
        "colab_type": "code",
        "outputId": "99454b0f-d260-4c04-b25d-98b4b6bf2b2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print_plot(30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chain expressions inside ngclass using form add another expression ngclass directive uses form ngclass true loading false loadingdone dataloadernull like add something like list highlightisspecial possible without expanding first expression thanks\n",
            "Tag: angularjs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7RNWHVBQ-i0",
        "colab_type": "code",
        "outputId": "5be1823b-ee52-419d-f058-73b4dc6d83e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df['post'].apply(lambda x: len(x.split(' '))).sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3424297"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpbXpizgAkv8",
        "colab_type": "text"
      },
      "source": [
        "### splitting dataset for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhvsSbvARDLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.post\n",
        "y = df.tags\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msiIGjeWA6fz",
        "colab_type": "text"
      },
      "source": [
        "## Naive Bayer Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWJi7KkkRGyJ",
        "colab_type": "code",
        "outputId": "6c57e47a-16ad-4e28-cf1b-8513b45d9dab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        }
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "nb = Pipeline([('vect', CountVectorizer()),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('clf', MultinomialNB()),\n",
        "              ])\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = nb.predict(X_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=my_tags))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.7395\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         java       0.63      0.65      0.64       613\n",
            "         html       0.94      0.86      0.90       620\n",
            "      asp.net       0.87      0.92      0.90       587\n",
            "           c#       0.70      0.77      0.73       586\n",
            "ruby-on-rails       0.73      0.87      0.79       599\n",
            "       jquery       0.72      0.51      0.60       589\n",
            "        mysql       0.77      0.74      0.75       594\n",
            "          php       0.69      0.89      0.78       610\n",
            "          ios       0.63      0.59      0.61       617\n",
            "   javascript       0.57      0.65      0.60       587\n",
            "       python       0.70      0.50      0.59       611\n",
            "            c       0.79      0.78      0.79       594\n",
            "          css       0.84      0.59      0.69       619\n",
            "      android       0.66      0.84      0.74       574\n",
            "       iphone       0.64      0.83      0.72       584\n",
            "          sql       0.66      0.64      0.65       578\n",
            "  objective-c       0.79      0.77      0.78       591\n",
            "          c++       0.89      0.83      0.86       608\n",
            "    angularjs       0.94      0.89      0.91       638\n",
            "         .net       0.74      0.66      0.70       601\n",
            "\n",
            "     accuracy                           0.74     12000\n",
            "    macro avg       0.74      0.74      0.74     12000\n",
            " weighted avg       0.75      0.74      0.74     12000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XNssE4uA_T-",
        "colab_type": "text"
      },
      "source": [
        "## Linear Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW79J-RXRPHk",
        "colab_type": "code",
        "outputId": "1e738d89-1bd3-4dcb-c517-7d0c04bf0318",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        }
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
        "               ])\n",
        "sgd.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = sgd.predict(X_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=my_tags))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.7895833333333333\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         java       0.73      0.67      0.70       613\n",
            "         html       0.84      0.94      0.89       620\n",
            "      asp.net       0.88      0.95      0.92       587\n",
            "           c#       0.81      0.80      0.80       586\n",
            "ruby-on-rails       0.73      0.89      0.80       599\n",
            "       jquery       0.77      0.39      0.52       589\n",
            "        mysql       0.81      0.69      0.74       594\n",
            "          php       0.71      0.95      0.81       610\n",
            "          ios       0.83      0.57      0.67       617\n",
            "   javascript       0.72      0.58      0.64       587\n",
            "       python       0.71      0.65      0.68       611\n",
            "            c       0.79      0.88      0.83       594\n",
            "          css       0.77      0.79      0.78       619\n",
            "      android       0.84      0.86      0.85       574\n",
            "       iphone       0.82      0.81      0.81       584\n",
            "          sql       0.70      0.68      0.69       578\n",
            "  objective-c       0.81      0.90      0.85       591\n",
            "          c++       0.84      0.96      0.90       608\n",
            "    angularjs       0.87      0.96      0.91       638\n",
            "         .net       0.78      0.88      0.83       601\n",
            "\n",
            "     accuracy                           0.79     12000\n",
            "    macro avg       0.79      0.79      0.78     12000\n",
            " weighted avg       0.79      0.79      0.78     12000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANPSWkdJBQeA",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkOc6Gw9RV8L",
        "colab_type": "code",
        "outputId": "8aa086ca-0be8-468a-8eb3-44ef22594acb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
        "               ])\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=my_tags))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.78175\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         java       0.70      0.62      0.66       613\n",
            "         html       0.91      0.91      0.91       620\n",
            "      asp.net       0.97      0.94      0.95       587\n",
            "           c#       0.77      0.77      0.77       586\n",
            "ruby-on-rails       0.77      0.81      0.79       599\n",
            "       jquery       0.59      0.58      0.59       589\n",
            "        mysql       0.78      0.75      0.76       594\n",
            "          php       0.82      0.85      0.83       610\n",
            "          ios       0.69      0.71      0.70       617\n",
            "   javascript       0.61      0.59      0.60       587\n",
            "       python       0.64      0.63      0.63       611\n",
            "            c       0.82      0.83      0.83       594\n",
            "          css       0.78      0.78      0.78       619\n",
            "      android       0.84      0.85      0.84       574\n",
            "       iphone       0.80      0.83      0.82       584\n",
            "          sql       0.65      0.64      0.65       578\n",
            "  objective-c       0.82      0.85      0.83       591\n",
            "          c++       0.91      0.91      0.91       608\n",
            "    angularjs       0.96      0.94      0.95       638\n",
            "         .net       0.78      0.83      0.80       601\n",
            "\n",
            "     accuracy                           0.78     12000\n",
            "    macro avg       0.78      0.78      0.78     12000\n",
            " weighted avg       0.78      0.78      0.78     12000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZffJ4yBBX15",
        "colab_type": "text"
      },
      "source": [
        "## Word2Vec & embeddings\n",
        "Word2vec is a type of mapping that allows words with similar meaning to have similar vector representation.\n",
        "\n",
        "The idea behind Word2vec is rather simple: we want to use the surrounding words to represent the target words with a Neural Network whose hidden layer encodes the word representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7j4nOMwBdw4",
        "colab_type": "text"
      },
      "source": [
        "### loading precomputed embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FttqZMv3TM0H",
        "colab_type": "code",
        "outputId": "16d6d83c-8057-4e9e-c158-02f4ccfec96b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gSsTgezRfUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "wv = gensim.models.KeyedVectors.load_word2vec_format(\"/content/drive/My Drive/Colab Notebooks/GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
        "wv.init_sims(replace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJvOq1kOSMkh",
        "colab_type": "code",
        "outputId": "c66430d4-763a-4f8a-bf28-fa3db14f5880",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "from itertools import islice\n",
        "list(islice(wv.vocab, 13030, 13050))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Memorial_Hospital',\n",
              " 'Seniors',\n",
              " 'memorandum',\n",
              " 'elephant',\n",
              " 'Trump',\n",
              " 'Census',\n",
              " 'pilgrims',\n",
              " 'De',\n",
              " 'Dogs',\n",
              " '###-####_ext',\n",
              " 'chaotic',\n",
              " 'forgive',\n",
              " 'scholar',\n",
              " 'Lottery',\n",
              " 'decreasing',\n",
              " 'Supervisor',\n",
              " 'fundamentally',\n",
              " 'Fitness',\n",
              " 'abundance',\n",
              " 'Hold']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaER5YrRTn7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BOW based approaches that includes averaging, summation, weighted addition. The common way is to average the two word vectors. Therefore, we will follow the most common way.\n",
        "\n",
        "def word_averaging(wv, words):\n",
        "    all_words, mean = set(), []\n",
        "    \n",
        "    for word in words:\n",
        "        if isinstance(word, np.ndarray):\n",
        "            mean.append(word)\n",
        "        elif word in wv.vocab:\n",
        "            mean.append(wv.syn0norm[wv.vocab[word].index])\n",
        "            all_words.add(wv.vocab[word].index)\n",
        "\n",
        "    if not mean:\n",
        "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
        "        # FIXME: remove these examples in pre-processing\n",
        "        return np.zeros(wv.vector_size,)\n",
        "\n",
        "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
        "    return mean\n",
        "\n",
        "def  word_averaging_list(wv, text_list):\n",
        "    return np.vstack([word_averaging(wv, post) for post in text_list ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0bVxlbjTwJq",
        "colab_type": "code",
        "outputId": "e5ebc7a2-244a-4e3a-f9df-8dc1fe71fb39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "# We will tokenize the text and apply the tokenization to “post” column, and apply word vector averaging to tokenized text.\n",
        "\n",
        "def w2v_tokenize_text(text):\n",
        "    tokens = []\n",
        "    for sent in nltk.sent_tokenize(text, language='english'):\n",
        "        for word in nltk.word_tokenize(sent, language='english'):\n",
        "            if len(word) < 2:\n",
        "                continue\n",
        "            tokens.append(word)\n",
        "    return tokens\n",
        "    \n",
        "train, test = train_test_split(df, test_size=0.3, random_state = 42)\n",
        "\n",
        "test_tokenized = test.apply(lambda r: w2v_tokenize_text(r['post']), axis=1).values\n",
        "train_tokenized = train.apply(lambda r: w2v_tokenize_text(r['post']), axis=1).values\n",
        "\n",
        "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
        "X_test_word_average = word_averaging_list(wv,test_tokenized)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.wv.vectors_norm instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n",
            "WARNING:root:cannot compute similarity with no input []\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoddfH2JCjCb",
        "colab_type": "text"
      },
      "source": [
        "### word2vec & logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8KVhtHhT5EH",
        "colab_type": "code",
        "outputId": "d6238071-e911-4f9e-a8b3-83d92c9c973e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
        "logreg = logreg.fit(X_train_word_average, train['tags'])\n",
        "y_pred = logreg.predict(X_test_word_average)\n",
        "print('accuracy %s' % accuracy_score(y_pred, test.tags))\n",
        "print(classification_report(test.tags, y_pred,target_names=my_tags))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.6380833333333333\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         java       0.63      0.59      0.61       613\n",
            "         html       0.74      0.76      0.75       620\n",
            "      asp.net       0.65      0.67      0.66       587\n",
            "           c#       0.53      0.52      0.52       586\n",
            "ruby-on-rails       0.70      0.77      0.73       599\n",
            "       jquery       0.44      0.39      0.41       589\n",
            "        mysql       0.65      0.60      0.63       594\n",
            "          php       0.73      0.80      0.76       610\n",
            "          ios       0.61      0.61      0.61       617\n",
            "   javascript       0.56      0.52      0.54       587\n",
            "       python       0.55      0.50      0.52       611\n",
            "            c       0.61      0.61      0.61       594\n",
            "          css       0.65      0.65      0.65       619\n",
            "      android       0.61      0.57      0.59       574\n",
            "       iphone       0.70      0.71      0.70       584\n",
            "          sql       0.43      0.43      0.43       578\n",
            "  objective-c       0.68      0.71      0.70       591\n",
            "          c++       0.76      0.78      0.77       608\n",
            "    angularjs       0.82      0.83      0.82       638\n",
            "         .net       0.65      0.71      0.68       601\n",
            "\n",
            "     accuracy                           0.64     12000\n",
            "    macro avg       0.63      0.64      0.63     12000\n",
            " weighted avg       0.63      0.64      0.64     12000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKy6KRiXCtIH",
        "colab_type": "text"
      },
      "source": [
        "### Doc2Vec & Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEDsaNkIT-nV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "tqdm.pandas(desc=\"progress-bar\")\n",
        "from gensim.models import Doc2Vec\n",
        "from sklearn import utils\n",
        "import gensim\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import re\n",
        "\n",
        "def label_sentences(corpus, label_type):\n",
        "    \"\"\"\n",
        "    Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
        "    We do this by using the TaggedDocument method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
        "    a dummy index of the post.\n",
        "    \"\"\"\n",
        "    labeled = []\n",
        "    for i, v in enumerate(corpus):\n",
        "        label = label_type + '_' + str(i)\n",
        "        labeled.append(TaggedDocument(v.split(), [label]))\n",
        "    return labeled\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.post, df.tags, random_state=0, test_size=0.3)\n",
        "X_train = label_sentences(X_train, 'Train')\n",
        "X_test = label_sentences(X_test, 'Test')\n",
        "all_data = X_train + X_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ipqv_CtEUEnw",
        "colab_type": "code",
        "outputId": "022d9ef8-7fe3-439b-c002-8bdbfbc1bcff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "all_data[:2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TaggedDocument(words=['fulltext', 'search', 'php', 'pdo', 'returning', 'result', 'searched', 'lot', 'matter', 'find', 'wrong', 'setup', 'trying', 'fulltext', 'search', 'using', 'pdo', 'php', 'get', 'results', 'error', 'messages', 'table', 'contains', 'customer', 'details', 'id', 'int', '11', 'auto_increment', 'name', 'varchar', '150', 'lastname', 'varchar', '150', 'company', 'varchar', '250', 'adress', 'varchar', '150', 'postcode', 'int', '5', 'city', 'varchar', '150', 'email', 'varchar', '250', 'phone', 'varchar', '20', 'orgnr', 'varchar', '15', 'timestamp', 'timestamp', 'current_timestamp', 'run', 'sqlquery', 'alter', 'table', 'system_customer', 'add', 'fulltext', 'name', 'lastname', 'except', 'columns', 'id', 'postcode', 'timestamp', 'signs', 'trouble', 'far', 'idea', 'problem', 'lies', 'db', 'configuration', 'php', 'code', 'goes', 'php', 'sth', 'dbhprepare', 'select', 'name', 'lastname', 'company', 'adress', 'city', 'phone', 'email', 'orgnr', 'db_pre', 'customer', 'match', 'name', 'lastname', 'company', 'adress', 'city', 'phone', 'email', 'orgnr', 'search', 'boolean', 'mode', 'bind', 'placeholders', 'sthbindparam', 'search', 'data', 'sthexecute', 'rows', 'sthfetchall', 'testing', 'print_r', 'dbherrorinfo', 'empty', 'rows', 'echo', 'else', 'echo', 'foreach', 'rows', 'row', 'echo', 'tr', 'datahref', 'new_orderphp', 'cid', 'row', 'id', 'echo', 'td', 'row', 'name', 'td', 'echo', 'td', 'row', 'lastname', 'td', 'echo', 'td', 'row', 'company', 'td', 'echo', 'td', 'row', 'phone', 'td', 'echo', 'td', 'row', 'email', 'td', 'echo', 'td', 'date', 'ymd', 'strtotime', 'row', 'timestamp', 'td', 'echo', 'tr', 'echo', 'tried', 'change', 'parameter', 'searchquery', 'string', 'like', 'testcompany', 'somename', 'boolean', 'mode', 'also', 'read', 'word', 'found', '50', 'rows', 'counts', 'common', 'word', 'pretty', 'sure', 'case', 'uses', 'specific', 'words', 'table', 'uses', 'myisam', 'engine', 'get', 'results', 'error', 'messages', 'please', 'help', 'point', 'wrong', 'thank'], tags=['Train_0']),\n",
              " TaggedDocument(words=['select', 'everything', '1', 'table', 'x', 'rows', 'another', 'im', 'making', 'join', 'query', 'like', 'select', 'clothes', 'c', 'join', 'style', 'cstyleid', 'ssylelid', 'clothesid', '19', 'dont', 'want', 'select', 'everything', 'style', 'want', 'select', 'everything', 'clothes', '20', 'rows', 'select', '1', 'row', '10', 'style', 'easyest', 'way', 'without', 'select', 'every', 'row', 'clothes', '20', 'things', 'select', 'like', 'select', 'cid', 'cdescription', 'cname', 'csize', 'cbrand', 'sname', 'clothes', 'c', 'join', 'style', 'cstyleid', 'stsylelid', 'clothesid', '19', 'would', 'fastest', 'way', 'possibillity'], tags=['Train_1'])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUqzbnxfUO1e",
        "colab_type": "code",
        "outputId": "56d9047a-cb2c-448e-b341-e8e179ecd146",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        }
      },
      "source": [
        "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
        "model_dbow.build_vocab([x for x in tqdm(all_data)])\n",
        "\n",
        "for epoch in range(30):\n",
        "    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), total_examples=len(all_data), epochs=1)\n",
        "    model_dbow.alpha -= 0.002\n",
        "    model_dbow.min_alpha = model_dbow.alpha"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40000/40000 [00:00<00:00, 2189208.21it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 2045378.36it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 2364220.23it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 2926428.75it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 2216804.00it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 2768654.55it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 2078265.76it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 2852831.37it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 2296801.47it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 2084670.04it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 2579046.92it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 2224121.54it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 2129007.27it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 2846538.96it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 2808372.28it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 2537542.50it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 2706613.75it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 2849391.30it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 2892423.97it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 2754969.95it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 2705173.58it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 2803819.71it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 1432872.37it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 2718234.64it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 2457048.12it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 2832123.43it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 2757641.64it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 2187467.05it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 2793595.31it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 1600696.10it/s]\n",
            "100%|██████████| 40000/40000 [00:00<00:00, 2274784.21it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q7Fuef7UUyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
        "    \"\"\"\n",
        "    Get vectors from trained doc2vec model\n",
        "    :param doc2vec_model: Trained Doc2Vec model\n",
        "    :param corpus_size: Size of the data\n",
        "    :param vectors_size: Size of the embedding vectors\n",
        "    :param vectors_type: Training or Testing vectors\n",
        "    :return: list of vectors\n",
        "    \"\"\"\n",
        "    vectors = np.zeros((corpus_size, vectors_size))\n",
        "    for i in range(0, corpus_size):\n",
        "        prefix = vectors_type + '_' + str(i)\n",
        "        vectors[i] = model.docvecs[prefix]\n",
        "    return vectors\n",
        "    \n",
        "train_vectors_dbow = get_vectors(model_dbow, len(X_train), 300, 'Train')\n",
        "test_vectors_dbow = get_vectors(model_dbow, len(X_test), 300, 'Test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpYm7lEfUa9b",
        "colab_type": "code",
        "outputId": "fdead3f0-0b72-4647-d929-45d2b07dc3ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        }
      },
      "source": [
        "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
        "logreg.fit(train_vectors_dbow, y_train)\n",
        "logreg = logreg.fit(train_vectors_dbow, y_train)\n",
        "y_pred = logreg.predict(test_vectors_dbow)\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=my_tags))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.8068333333333333\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         java       0.71      0.69      0.70       589\n",
            "         html       0.89      0.91      0.90       661\n",
            "      asp.net       0.93      0.95      0.94       606\n",
            "           c#       0.81      0.78      0.79       613\n",
            "ruby-on-rails       0.84      0.89      0.86       601\n",
            "       jquery       0.71      0.73      0.72       585\n",
            "        mysql       0.87      0.81      0.84       621\n",
            "          php       0.81      0.84      0.83       587\n",
            "          ios       0.70      0.65      0.67       560\n",
            "   javascript       0.67      0.65      0.66       611\n",
            "       python       0.67      0.68      0.68       593\n",
            "            c       0.80      0.84      0.82       581\n",
            "          css       0.82      0.77      0.79       608\n",
            "      android       0.83      0.85      0.84       593\n",
            "       iphone       0.82      0.82      0.82       592\n",
            "          sql       0.74      0.67      0.70       597\n",
            "  objective-c       0.84      0.87      0.86       604\n",
            "          c++       0.89      0.94      0.92       610\n",
            "    angularjs       0.94      0.95      0.95       595\n",
            "         .net       0.80      0.81      0.81       593\n",
            "\n",
            "     accuracy                           0.81     12000\n",
            "    macro avg       0.80      0.81      0.80     12000\n",
            " weighted avg       0.81      0.81      0.81     12000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38ZCvS4mC2MS",
        "colab_type": "text"
      },
      "source": [
        "## Keras Bag of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyOq3RDDUjqu",
        "colab_type": "code",
        "outputId": "dbcbf657-bebb-4816-b60c-5aa6e360b116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "import itertools\n",
        "import os\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import utils\n",
        "\n",
        "train_size = int(len(df) * .7)\n",
        "train_posts = df['post'][:train_size]\n",
        "train_tags = df['tags'][:train_size]\n",
        "\n",
        "test_posts = df['post'][train_size:]\n",
        "test_tags = df['tags'][train_size:]\n",
        "\n",
        "max_words = 1000\n",
        "tokenize = text.Tokenizer(num_words=max_words, char_level=False)\n",
        "tokenize.fit_on_texts(train_posts) # only fit on train\n",
        "\n",
        "x_train = tokenize.texts_to_matrix(train_posts)\n",
        "x_test = tokenize.texts_to_matrix(test_posts)\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(train_tags)\n",
        "y_train = encoder.transform(train_tags)\n",
        "y_test = encoder.transform(test_tags)\n",
        "\n",
        "num_classes = np.max(y_train) + 1\n",
        "y_train = utils.to_categorical(y_train, num_classes)\n",
        "y_test = utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 2\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_shape=(max_words,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "              \n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 25200 samples, validate on 2800 samples\n",
            "Epoch 1/2\n",
            "25200/25200 [==============================] - 4s 175us/step - loss: 1.0254 - acc: 0.7146 - val_loss: 0.6776 - val_acc: 0.7850\n",
            "Epoch 2/2\n",
            "25200/25200 [==============================] - 3s 102us/step - loss: 0.5670 - acc: 0.8195 - val_loss: 0.6497 - val_acc: 0.7982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6tqef3vUtzU",
        "colab_type": "code",
        "outputId": "a12ba0d7-6ee6-48b2-9388-bc661fcee838",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "score = model.evaluate(x_test, y_test,\n",
        "                       batch_size=batch_size, verbose=1)\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12000/12000 [==============================] - 0s 36us/step\n",
            "Test accuracy: 0.794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAmW749FU74E",
        "colab_type": "text"
      },
      "source": [
        "Notes :\n",
        "* https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568\n",
        "* https://towardsdatascience.com/multi-class-text-classification-with-doc2vec-logistic-regression-9da9947b43f4\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NVuVpqDU84m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}